{"99":
 "<code class=\"docstring\">* `change tgt'` will change the goal from `tgt` to `tgt'`,\n  assuming these are definitionally equal.\n* `change t' at h` will change hypothesis `h : t` to have type `t'`, assuming\n  assuming `t` and `t'` are definitionally equal.\n</code>",
 "98":
 "<code>Verso.Genre.Manual.conv : Verso.Doc.Elab.DirectiveExpander</code>",
 "97":
 "<code>Trans.{u, v, w, u_1, u_2, u_3} {α : Sort u_1} {β : Sort u_2} {γ : Sort u_3} (r : α → β → Sort u) (s : β → γ → Sort v)\n  (t : outParam (α → γ → Sort w)) : Sort (max (max (max (max (max (max 1 u) u_1) u_2) u_3) v) w)</code><span class=\"sep\"></span><code class=\"docstring\">Transitive chaining of proofs, used e.g. by `calc`.\n\nIt takes two relations `r` and `s` as \"input\", and produces an \"output\"\nrelation `t`, with the property that `r a b` and `s b c` implies `t a c`.\nThe `calc` tactic uses this so that when it sees a chain with `a ≤ b` and `b &lt; c`\nit knows that this should be a proof of `a &lt; c` because there is an instance\n`Trans (·≤·) (·&lt;·) (·&lt;·)`.\n</code>",
 "96": "<code>?m.25</code>",
 "95":
 "<code>add_assoc.{u_1} {G : Type u_1} [AddSemigroup G] (a b c : G) : a + b + c = a + (b + c)</code>",
 "94":
 "<code>mul_one.{u} {M : Type u} [MulOneClass M] (a : M) : a * 1 = a</code>",
 "93":
 "<code>mul_add.{v} {R : Type v} [Mul R] [Add R] [LeftDistribClass R] (a b c : R) : a * (b + c) = a * b + a * c</code><span class=\"sep\"></span><code class=\"docstring\">**Alias** of `left_distrib`.</code>",
 "92":
 "<code>pow_two.{u_2} {M : Type u_2} [Monoid M] (a : M) : a ^ 2 = a * a</code><span class=\"sep\"></span><code class=\"docstring\">Note that most of the lemmas about powers of two refer to it as `sq`. </code>",
 "91":
 "<code class=\"docstring\">Step-wise reasoning over transitive relations.\n```\ncalc\n  a = b := pab\n  b = c := pbc\n  ...\n  y = z := pyz\n```\nproves `a = z` from the given step-wise proofs. `=` can be replaced with any\nrelation implementing the typeclass `Trans`. Instead of repeating the right-\nhand sides, subsequent left-hand sides can be replaced with `_`.\n```\ncalc\n  a = b := pab\n  _ = c := pbc\n  ...\n  _ = z := pyz\n```\nIt is also possible to write the *first* relation as `&lt;lhs&gt;\\n  _ = &lt;rhs&gt; :=\n&lt;proof&gt;`. This is useful for aligning relation symbols, especially on longer:\nidentifiers:\n```\ncalc abc\n  _ = bce := pabce\n  _ = cef := pbcef\n  ...\n  _ = xyz := pwxyz\n```\n\n`calc` works as a term, as a tactic or as a `conv` tactic.\n\nSee [Theorem Proving in Lean 4][tpil4] for more information.\n\n[tpil4]: https://lean-lang.org/theorem_proving_in_lean4/quantifiers_and_equality.html#calculational-proofs\n</code>",
 "90":
 "<code>add_mul.{v} {R : Type v} [Mul R] [Add R] [RightDistribClass R] (a b c : R) : (a + b) * c = a * c + b * c</code><span class=\"sep\"></span><code class=\"docstring\">**Alias** of `right_distrib`.</code>",
 "9": "<code>s ⊆ t</code>",
 "89":
 "<code>one_mul.{u} {M : Type u} [MulOneClass M] (a : M) : 1 * a = a</code>",
 "88":
 "<code class=\"docstring\">`nth_rewrite` is a variant of `rewrite` that only changes the `n₁, ..., nₖ`ᵗʰ _occurrence_ of\nthe expression to be rewritten. `nth_rewrite n₁ ... nₖ [eq₁, eq₂,..., eqₘ]` will rewrite the\n`n₁, ..., nₖ`ᵗʰ _occurrence_ of each of the `m` equalities `eqᵢ`in that order. Occurrences are\ncounted beginning with `1` in order of precedence.\n\nFor example,\n```lean\nexample (h : a = 1) : a + a + a + a + a = 5 := by\n  nth_rewrite 2 3 [h]\n/-\na: ℕ\nh: a = 1\n⊢ a + 1 + 1 + a + a = 5\n-/\n```\nNotice that the second occurrence of `a` from the left has been rewritten by `nth_rewrite`.\n\nTo understand the importance of order of precedence, consider the example below\n```lean\nexample (a b c : Nat) : (a + b) + c = (b + a) + c := by\n  nth_rewrite 2 [Nat.add_comm] -- ⊢ (b + a) + c = (b + a) + c\n```\nHere, although the occurrence parameter is `2`, `(a + b)` is rewritten to `(b + a)`. This happens\nbecause in order of precedence, the first occurrence of `_ + _` is the one that adds `a + b` to `c`.\nThe occurrence in `a + b` counts as the second occurrence.\n\nIf a term `t` is introduced by rewriting with `eqᵢ`, then this instance of `t` will be counted as an\n_occurrence_ of `t` for all subsequent rewrites of `t` with `eqⱼ` for `j &gt; i`. This behaviour is\nillustrated by the example below\n```lean\nexample (h : a = a + b) : a + a + a + a + a = 0 := by\n  nth_rewrite 3 [h, h]\n/-\na b: ℕ\nh: a = a + b\n⊢ a + a + (a + b + b) + a + a = 0\n-/\n```\nHere, the first `nth_rewrite` with `h` introduces an additional occurrence of `a` in the goal.\nThat is, the goal state after the first rewrite looks like below\n```lean\n/-\na b: ℕ\nh: a = a + b\n⊢ a + a + (a + b) + a + a = 0\n-/\n```\nThis new instance of `a` also turns out to be the third _occurrence_ of `a`.  Therefore,\nthe next `nth_rewrite` with `h` rewrites this `a`.\n</code>",
 "87": "<code>n + n = 2 * n</code>",
 "86": "<code>p</code>",
 "85":
 "<code class=\"docstring\">`by_cases (h :)? p` splits the main goal into two cases, assuming `h : p` in the first branch, and `h : ¬ p` in the second branch.\n</code>",
 "84": "<code>¬P → Q</code>",
 "83":
 "<code>True : Prop</code><span class=\"sep\"></span><code class=\"docstring\">`True` is a proposition and has only an introduction rule, `True.intro : True`.\nIn other words, `True` is simply true, and has a canonical proof, `True.intro`\nFor more information: [Propositional Logic](https://lean-lang.org/theorem_proving_in_lean4/propositions_and_proofs.html#propositional-logic)\n</code>",
 "82":
 "<code>bool.{u, v} {β : Type u} {α : Type v} [ToBool β] (f t : α) (b : β) : α</code>",
 "81":
 "<code>Bool.false : Bool</code><span class=\"sep\"></span><code class=\"docstring\">The boolean value `false`, not to be confused with the proposition `False`. </code>",
 "80":
 "<code>Bool.true : Bool</code><span class=\"sep\"></span><code class=\"docstring\">The boolean value `true`, not to be confused with the proposition `True`. </code>",
 "8":
 "<code>Set.{u} (α : Type u) : Type u</code><span class=\"sep\"></span><code class=\"docstring\">A set is a collection of elements of some type `α`.\n\nAlthough `Set` is defined as `α → Prop`, this is an implementation detail which should not be\nrelied on. Instead, `setOf` and membership of a set (`∈`) should be used to convert between sets\nand predicates.\n</code>",
 "79":
 "<code>Bool : Type</code><span class=\"sep\"></span><code class=\"docstring\">`Bool` is the type of boolean values, `true` and `false`. Classically,\nthis is equivalent to `Prop` (the type of propositions), but the distinction\nis important for programming, because values of type `Prop` are erased in the\ncode generator, while `Bool` corresponds to the type called `bool` or `boolean`\nin most programming languages.\n</code>",
 "78":
 "<code class=\"docstring\">`assumption` tries to solve the main goal using a hypothesis of compatible type, or else fails.\nNote also the `‹t›` term notation, which is a shorthand for `show t by assumption`.\n</code>",
 "77":
 "<code class=\"docstring\">If the main goal's target type is an inductive type, `constructor` solves it with\nthe first matching constructor, or else fails.\n</code>",
 "76":
 "<code class=\"docstring\">`solve_by_elim` calls `apply` on the main goal to find an assumption whose head matches\nand then repeatedly calls `apply` on the generated subgoals until no subgoals remain,\nperforming at most `maxDepth` (defaults to 6) recursive steps.\n\n`solve_by_elim` discharges the current goal or fails.\n\n`solve_by_elim` performs backtracking if subgoals can not be solved.\n\nBy default, the assumptions passed to `apply` are the local context, `rfl`, `trivial`,\n`congrFun` and `congrArg`.\n\nThe assumptions can be modified with similar syntax as for `simp`:\n* `solve_by_elim [h₁, h₂, ..., hᵣ]` also applies the given expressions.\n* `solve_by_elim only [h₁, h₂, ..., hᵣ]` does not include the local context,\n  `rfl`, `trivial`, `congrFun`, or `congrArg` unless they are explicitly included.\n* `solve_by_elim [-h₁, ... -hₙ]` removes the given local hypotheses.\n* `solve_by_elim using [a₁, ...]` uses all lemmas which have been labelled\n  with the attributes `aᵢ` (these attributes must be created using `register_label_attr`).\n\n`solve_by_elim*` tries to solve all goals together, using backtracking if a solution for one goal\nmakes other goals impossible.\n(Adding or removing local hypotheses may not be well-behaved when starting with multiple goals.)\n\nOptional arguments passed via a configuration argument as `solve_by_elim (config := { ... })`\n- `maxDepth`: number of attempts at discharging generated subgoals\n- `symm`: adds all hypotheses derived by `symm` (defaults to `true`).\n- `exfalso`: allow calling `exfalso` and trying again if `solve_by_elim` fails\n  (defaults to `true`).\n- `transparency`: change the transparency mode when calling `apply`. Defaults to `.default`,\n  but it is often useful to change to `.reducible`,\n  so semireducible definitions will not be unfolded when trying to apply a lemma.\n\nSee also the doc-comment for `Lean.Meta.Tactic.Backtrack.BacktrackConfig` for the options\n`proc`, `suspend`, and `discharge` which allow further customization of `solve_by_elim`.\nBoth `apply_assumption` and `apply_rules` are implemented via these hooks.\n</code>",
 "75":
 "<code class=\"docstring\">`apply t at i` will use forward reasoning with `t` at the hypothesis `i`.\nExplicitly, if `t : α₁ → ⋯ → αᵢ → ⋯ → αₙ` and `i` has type `αᵢ`, then this tactic will add\nmetavariables/goals for any terms of `αⱼ` for `j = 1, …, i-1`,\nthen replace the type of `i` with `αᵢ₊₁ → ⋯ → αₙ` by applying those metavariables and the\noriginal `i`.\n</code>",
 "74":
 "<code>Lean.ParserDescr : Type</code><span class=\"sep\"></span><code class=\"docstring\">A `ParserDescr` is a grammar for parsers. This is used by the `syntax` command\nto produce parsers without having to `import Lean`.\n</code>",
 "73": "<code>Nat.zero_lt_two : 0 &lt; 2</code>",
 "72": "<code>∀ (k : ℕ), k ≤ 2 * k</code>",
 "71":
 "<code>le_trans.{u_1} {α : Type u_1} [Preorder α] {a b c : α} : a ≤ b → b ≤ c → a ≤ c</code><span class=\"sep\"></span><code class=\"docstring\">The relation `≤` on a preorder is transitive. </code>",
 "70":
 "<code>Nat.le_mul_of_pos_left {n : ℕ} (m : ℕ) (h : 0 &lt; n) : m ≤ n * m</code>",
 "7": "<code>Set ℝ</code>",
 "69": "<code>n ≤ n * n</code>",
 "68":
 "<code>LE.le.{u} {α : Type u} [self : LE α] : α → α → Prop</code><span class=\"sep\"></span><code class=\"docstring\">The less-equal relation: `x ≤ y` </code>",
 "67": "<code>0 &lt; n</code>",
 "66": "<code>Sort ?u.37</code>",
 "65": "<code>Sort ?u.31</code>",
 "64": "<code>Sort ?u.27</code>",
 "63": "<code>P → Q → R</code>",
 "62": "<code>Nat.lt_of_succ_le {n m : ℕ} (h : n.succ ≤ m) : n &lt; m</code>",
 "61":
 "<code>HPow.hPow.{u, v, w} {α : Type u} {β : Type v} {γ : outParam (Type w)} [self : HPow α β γ] : α → β → γ</code><span class=\"sep\"></span><code class=\"docstring\">`a ^ b` computes `a` to the power of `b`.\nThe meaning of this notation is type-dependent. </code>",
 "60":
 "<code class=\"docstring\">This tactic applies to a goal whose target has the form `x ~ x`,\nwhere `~` is equality, heterogeneous equality or any relation that\nhas a reflexivity lemma tagged with the attribute @[refl].\n</code>",
 "6":
 "<code class=\"docstring\">`exact e` closes the main goal if its target type matches that of `e`.\n</code>",
 "59":
 "<code>Exists.intro.{u} {α : Sort u} {p : α → Prop} (w : α) (h : p w) : Exists p</code><span class=\"sep\"></span><code class=\"docstring\">Existential introduction. If `a : α` and `h : p a`,\nthen `⟨a, h⟩` is a proof that `∃ x : α, p x`. </code>",
 "58":
 "<code class=\"docstring\">`refine e` behaves like `exact e`, except that named (`?x`) or unnamed (`?_`)\nholes in `e` that are not solved by unification with the main goal's target type\nare converted into new goals, using the hole's name, if any, as the goal case name.\n</code>",
 "57":
 "<code class=\"docstring\">Tactic for evaluating expressions in *commutative* (semi)rings, allowing for variables in the\nexponent. If the goal is not appropriate for `ring` (e.g. not an equality) `ring_nf` will be\nsuggested.\n\n* `ring!` will use a more aggressive reducibility setting to determine equality of atoms.\n* `ring1` fails if the target is not an equality.\n\nFor example:\n```\nexample (n : ℕ) (m : ℤ) : 2^(n+1) * m = 2 * 2^n * m := by ring\nexample (a b : ℤ) (n : ℕ) : (a + b)^(n + 2) = (a^2 + b^2 + a * b + b * a) * (a + b)^n := by ring\nexample (x y : ℕ) : x + id y = y + id x := by ring!\nexample (x : ℕ) (h : x * 2 &gt; 5): x + x &gt; 5 := by ring; assumption -- suggests ring_nf\n```\n</code>",
 "56":
 "<code class=\"docstring\">`use e₁, e₂, ⋯` is similar to `exists`, but unlike `exists` it is equivalent to applying the tactic\n`refine ⟨e₁, e₂, ⋯, ?_, ⋯, ?_⟩` with any number of placeholders (rather than just one) and\nthen trying to close goals associated to the placeholders with a configurable discharger (rather\nthan just `try trivial`).\n\nExamples:\n\n```lean\nexample : ∃ x : Nat, x = x := by use 42\n\nexample : ∃ x : Nat, ∃ y : Nat, x = y := by use 42, 42\n\nexample : ∃ x : String × String, x.1 = x.2 := by use (\"forty-two\", \"forty-two\")\n```\n\n`use! e₁, e₂, ⋯` is similar but it applies constructors everywhere rather than just for\ngoals that correspond to the last argument of a constructor. This gives the effect that\nnested constructors are being flattened out, with the supplied values being used along the\nleaves and nodes of the tree of constructors.\nWith `use!` one can feed in each `42` one at a time:\n\n```lean\nexample : ∃ p : Nat × Nat, p.1 = p.2 := by use! 42, 42\n\nexample : ∃ p : Nat × Nat, p.1 = p.2 := by use! (42, 42)\n```\n\nThe second line makes use of the fact that `use!` tries refining with the argument before\napplying a constructor. Also note that `use`/`use!` by default uses a tactic\ncalled `use_discharger` to discharge goals, so `use! 42` will close the goal in this example since\n`use_discharger` applies `rfl`, which as a consequence solves for the other `Nat` metavariable.\n\nThese tactics take an optional discharger to handle remaining explicit `Prop` constructor arguments.\nBy default it is `use (discharger := try with_reducible use_discharger) e₁, e₂, ⋯`.\nTo turn off the discharger and keep all goals, use `(discharger := skip)`.\nTo allow \"heavy refls\", use `(discharger := try use_discharger)`.\n</code>",
 "55":
 "<code class=\"docstring\">The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or\nnon-dependent hypotheses. It has many variants:\n- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.\n- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged\n  with the attribute `[simp]` and the given `hᵢ`'s, where the `hᵢ`'s are expressions.-\n- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated\n  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.\n- `simp [*]` simplifies the main goal target using the lemmas tagged with the\n  attribute `[simp]` and all hypotheses.\n- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.\n- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged\n  with the attribute `[simp]`, but removes the ones named `idᵢ`.\n- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If\n  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis\n  `hᵢ` is introduced, but the old one remains in the local context.\n- `simp at *` simplifies all the hypotheses and the target.\n- `simp [*] at *` simplifies target and all (propositional) hypotheses using the\n  other hypotheses.\n</code>",
 "54": "<code>n = k + k</code>",
 "53":
 "<code class=\"docstring\">The `obtain` tactic is a combination of `have` and `rcases`. See `rcases` for\na description of supported patterns.\n\n```lean\nobtain ⟨patt⟩ : type := proof\n```\nis equivalent to\n```lean\nhave h : type := proof\nrcases h with ⟨patt⟩\n```\n\nIf `⟨patt⟩` is omitted, `rcases` will try to infer the pattern.\n\nIf `type` is omitted, `:= proof` is required.\n</code>",
 "52": "<code>∃ n, Even n</code>",
 "51":
 "<code class=\"docstring\">The `have` tactic is for adding hypotheses to the local context of the main goal.\n* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.\n* `have h := e` uses the type of `e` for `t`.\n* `have : t := e` and `have := e` use `this` for the name of the hypothesis.\n* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,\n  where `_` stands for the tactics that follow this one.\n  It is convenient for types that have only one applicable constructor.\n  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the\n  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.\n</code>",
 "50":
 "<code>HMul.hMul.{u, v, w} {α : Type u} {β : Type v} {γ : outParam (Type w)} [self : HMul α β γ] : α → β → γ</code><span class=\"sep\"></span><code class=\"docstring\">`a * b` computes the product of `a` and `b`.\nThe meaning of this notation is type-dependent. </code>",
 "5":
 "<code class=\"docstring\">`by tac` constructs a term of the expected type by running the tactic(s) `tac`. </code>",
 "49":
 "<code class=\"docstring\">Searches environment for definitions or theorems that can refine the goal using `apply`\nwith conditions resolved when possible with `solve_by_elim`.\n\nThe optional `using` clause provides identifiers in the local context that must be\nused when closing the goal.\n</code>",
 "48":
 "<code class=\"docstring\">`simp?` takes the same arguments as `simp`, but reports an equivalent call to `simp only`\nthat would be sufficient to close the goal. This is useful for reducing the size of the simp\nset in a local invocation to speed up processing.\n```\nexample (x : Nat) : (if True then x + 2 else 3) = x + 2 := by\n  simp? -- prints \"Try this: simp only [ite_true]\"\n```\n\nThis command can also be used in `simp_all` and `dsimp`.\n</code>",
 "47":
 "<code>LT.lt.{u} {α : Type u} [self : LT α] : α → α → Prop</code><span class=\"sep\"></span><code class=\"docstring\">The less-than relation: `x &lt; y` </code>",
 "46":
 "<code class=\"docstring\">Location specifications are used by many tactics that can operate on either the\nhypotheses or the goal. It can have one of the forms:\n* 'empty' is not actually present in this syntax, but most tactics use\n  `(location)?` matchers. It means to target the goal only.\n* `at h₁ ... hₙ`: target the hypotheses `h₁`, ..., `hₙ`\n* `at h₁ h₂ ⊢`: target the hypotheses `h₁` and `h₂`, and the goal\n* `at *`: target all hypotheses and the goal\n</code>",
 "45":
 "<code class=\"docstring\">`rw` is like `rewrite`, but also tries to close the goal by \"cheap\" (reducible) `rfl` afterwards.\n</code>",
 "44":
 "<code>Iff (a b : Prop) : Prop</code><span class=\"sep\"></span><code class=\"docstring\">If and only if, or logical bi-implication. `a ↔ b` means that `a` implies `b` and vice versa.\nBy `propext`, this implies that `a` and `b` are equal and hence any expression involving `a`\nis equivalent to the corresponding expression with `b` instead.\n</code>",
 "43": "<code>P ↔ Q</code>",
 "42": "<code>Q</code>",
 "41": "<code>Sort ?u.28</code>",
 "40": "<code>Sort ?u.24</code>",
 "4":
 "<code>False.elim.{u} {C : Sort u} (h : False) : C</code><span class=\"sep\"></span><code class=\"docstring\">`False.elim : False → C` says that from `False`, any desired proposition\n`C` holds. Also known as ex falso quodlibet (EFQ) or the principle of explosion.\n\nThe target type is actually `C : Sort u` which means it works for both\npropositions and types. When executed, this acts like an \"unreachable\"\ninstruction: it is **undefined behavior** to run, but it will probably print\n\"unreachable code\". (You would need to construct a proof of false to run it\nanyway, which you can only do using `sorry` or unsound axioms.)\n</code>",
 "39": "<code>Sort ?u.23</code>",
 "38": "<code>Sort u_3</code>",
 "37": "<code>Q → R</code>",
 "36": "<code>Sort u_2</code>",
 "35": "<code>P → Q</code>",
 "34": "<code>Sort ?u.7</code>",
 "33": "<code>Sort u_1</code>",
 "32":
 "<code class=\"docstring\">The `sorry` tactic is a temporary placeholder for an incomplete tactic proof,\nclosing the main goal using `exact sorry`.\n\nThis is intended for stubbing-out incomplete parts of a proof while still having a syntactically correct proof skeleton.\nLean will give a warning whenever a proof uses `sorry`, so you aren't likely to miss it,\nbut you can double check if a theorem depends on `sorry` by looking for `sorryAx` in the output\nof the `#print axioms my_thm` command, the axiom used by the implementation of `sorry`.\n</code>",
 "31":
 "<code>HAdd.hAdd.{u, v, w} {α : Type u} {β : Type v} {γ : outParam (Type w)} [self : HAdd α β γ] : α → β → γ</code><span class=\"sep\"></span><code class=\"docstring\">`a + b` computes the sum of `a` and `b`.\nThe meaning of this notation is type-dependent. </code>",
 "30":
 "<code>And (a b : Prop) : Prop</code><span class=\"sep\"></span><code class=\"docstring\">`And a b`, or `a ∧ b`, is the conjunction of propositions. It can be\nconstructed and destructed like a pair: if `ha : a` and `hb : b` then\n`⟨ha, hb⟩ : a ∧ b`, and if `h : a ∧ b` then `h.left : a` and `h.right : b`.\n</code>",
 "3":
 "<code>False : Prop</code><span class=\"sep\"></span><code class=\"docstring\">`False` is the empty proposition. Thus, it has no introduction rules.\nIt represents a contradiction. `False` elimination rule, `False.rec`,\nexpresses the fact that anything follows from a contradiction.\nThis rule is sometimes called ex falso (short for ex falso sequitur quodlibet),\nor the principle of explosion.\nFor more information: [Propositional Logic](https://lean-lang.org/theorem_proving_in_lean4/propositions_and_proofs.html#propositional-logic)\n</code>",
 "29":
 "<code>Prime.{u_1} {M : Type u_1} [CommMonoidWithZero M] (p : M) : Prop</code><span class=\"sep\"></span><code class=\"docstring\">An element `p` of a commutative monoid with zero (e.g., a ring) is called *prime*,\nif it's not zero, not a unit, and `p ∣ a * b → p ∣ a ∨ p ∣ b` for all `a`, `b`. </code>",
 "28":
 "<code>Even.{u_2} {α : Type u_2} [Add α] (a : α) : Prop</code><span class=\"sep\"></span><code class=\"docstring\">An element `a` of a type `α` with addition satisfies `Even a` if `a = r + r`,\nfor some `r : α`.</code>",
 "27": "<code>Even n</code>",
 "26": "<code>n &gt; 2</code>",
 "25":
 "<code>goldbach (n : ℕ) (h₁ : n &gt; 2) (h₂ : Even n) : ∃ i j, Prime i ∧ Prime j ∧ n = i + j</code>",
 "24":
 "<code class=\"docstring\">`apply e` tries to match the current goal against the conclusion of `e`'s type.\nIf it succeeds, then the tactic returns as many subgoals as the number of premises that\nhave not been fixed by type inference or type class resolution.\nNon-dependent premises are added before dependent ones.\n\nThe `apply` tactic uses higher-order pattern matching, type class resolution,\nand first-order unification with dependent types.\n</code>",
 "236": "<code>Type ?u.7</code>",
 "235": "<code>Set α</code>",
 "234":
 "<code>Nat.Prime (p : ℕ) : Prop</code><span class=\"sep\"></span><code class=\"docstring\">`Nat.Prime p` means that `p` is a prime number, that is, a natural number\nat least 2 whose only divisors are `p` and `1`.\nThe theorem `Nat.prime_def` witnesses this description of a prime number. </code>",
 "233":
 "<code class=\"docstring\">`end` closes a `section` or `namespace` scope. If the scope is named `&lt;id&gt;`, it has to be closed\nwith `end &lt;id&gt;`. The `end` command is optional at the end of a file.\n</code>",
 "232":
 "<code>Set.subset_union_right.{u} {α : Type u} {s t : Set α} : t ⊆ s ∪ t</code>",
 "231": "<code>JoinedIn B x y</code>",
 "230":
 "<code>Set.subset_union_left.{u} {α : Type u} {s t : Set α} : s ⊆ s ∪ t</code>",
 "23":
 "<code>Not (a : Prop) : Prop</code><span class=\"sep\"></span><code class=\"docstring\">`Not p`, or `¬p`, is the negation of `p`. It is defined to be `p → False`,\nso if your goal is `¬p` you can use `intro h` to turn the goal into\n`h : p ⊢ False`, and if you have `hn : ¬p` and `h : p` then `hn h : False`\nand `(hn h).elim` will prove anything.\nFor more information: [Propositional Logic](https://lean-lang.org/theorem_proving_in_lean4/propositions_and_proofs.html#propositional-logic)\n</code>",
 "229":
 "<code>JoinedIn.mono.{u_1} {X : Type u_1} [TopologicalSpace X] {x y : X} {U V : Set X} (h : JoinedIn U x y) (hUV : U ⊆ V) :\n  JoinedIn V x y</code>",
 "228":
 "<code>IsPathConnected.joinedIn.{u_1} {X : Type u_1} [TopologicalSpace X] {F : Set X} (h : IsPathConnected F) (x : X) :\n  x ∈ F → ∀ y ∈ F, JoinedIn F x y</code>",
 "227": "<code>JoinedIn A x y</code>",
 "226": "<code>y ∈ B</code>",
 "225": "<code>y ∈ A ∪ B</code>",
 "224":
 "<code>Set.mem_union_left.{u} {α : Type u} {x : α} {a : Set α} (b : Set α) : x ∈ a → x ∈ a ∪ b</code>",
 "223": "<code>x ∈ B</code>",
 "222":
 "<code>Union.union.{u} {α : Type u} [self : Union α] : α → α → α</code><span class=\"sep\"></span><code class=\"docstring\">`a ∪ b` is the union of`a` and `b`. </code>",
 "221":
 "<code>Inter.inter.{u} {α : Type u} [self : Inter α] : α → α → α</code><span class=\"sep\"></span><code class=\"docstring\">`a ∩ b` is the intersection of`a` and `b`. </code>",
 "220": "<code>(A ∩ B).Nonempty</code>",
 "22": "<code>¬P</code>",
 "219": "<code>IsPathConnected B</code>",
 "218": "<code>IsPathConnected A</code>",
 "217":
 "<code>my_task.{u_1} {X : Type u_1} [TopologicalSpace X] {A B : Set X} (hA : IsPathConnected A) (hB : IsPathConnected B)\n  (hAB : (A ∩ B).Nonempty) : IsPathConnected (A ∪ B)</code><span class=\"sep\"></span><code class=\"docstring\">If `A` and `B` are path connected, and their intersetion\nis nonempty, `A ∪ B` is pathconnected.\n</code>",
 "216":
 "<code>γ 1 = y</code><span class=\"sep\"></span><code class=\"docstring\">The end point of a `Path`. </code>",
 "215":
 "<code>γ 0 = x</code><span class=\"sep\"></span><code class=\"docstring\">The start point of a `Path`. </code>",
 "214":
 "<code>Continuous γ</code><span class=\"sep\"></span><code class=\"docstring\">Proposition that `toFun` is continuous </code>",
 "213":
 "<code>↑(Icc 0 1) → X</code><span class=\"sep\"></span><code class=\"docstring\">The function `X → Y` </code>",
 "212": "<code>_root_.Path x y</code>",
 "211":
 "<code class=\"docstring\">The `let` tactic is for adding definitions to the local context of the main goal.\n* `let x : t := e` adds the definition `x : t := e` if `e` is a term of type `t`.\n* `let x := e` uses the type of `e` for `t`.\n* `let : t := e` and `let := e` use `this` for the name of the hypothesis.\n* `let pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,\n  where `_` stands for the tactics that follow this one.\n  It is convenient for types that let only one applicable constructor.\n  For example, given `p : α × β × γ`, `let ⟨x, y, z⟩ := p` produces the\n  local variables `x : α`, `y : β`, and `z : γ`.\n</code>",
 "210": "<code>∀ (t : ↑(Icc 0 1)), γ t ∈ A</code>",
 "21": "<code>P</code>",
 "209": "<code>γ 1 = y</code>",
 "208": "<code>γ 0 = x</code>",
 "207": "<code>Continuous γ</code>",
 "206": "<code>y ∈ A</code>",
 "205": "<code>x ∈ A</code>",
 "204":
 "<code>∀ (x y : X), x ∈ A → y ∈ A → ∃ γ, Continuous γ ∧ γ 0 = x ∧ γ 1 = y ∧ ∀ (t : ↑(Icc 0 1)), γ t ∈ A</code>",
 "203": "<code>A.Nonempty</code>",
 "202":
 "<code>Path.target.{u_1} {X : Type u_1} [TopologicalSpace X] {x y : X} (γ : _root_.Path x y) : γ 1 = y</code>",
 "201":
 "<code>Path.source.{u_1} {X : Type u_1} [TopologicalSpace X] {x y : X} (γ : _root_.Path x y) : γ 0 = x</code>",
 "200":
 "<code>Path.continuous.{u_1} {X : Type u_1} [TopologicalSpace X] {x y : X} (γ : _root_.Path x y) : Continuous ⇑γ</code>",
 "20":
 "<code>Eq.{u_1} {α : Sort u_1} : α → α → Prop</code><span class=\"sep\"></span><code class=\"docstring\">The equality relation. It has one introduction rule, `Eq.refl`.\nWe use `a = b` as notation for `Eq a b`.\nA fundamental property of equality is that it is an equivalence relation.\n```\nvariable (α : Type) (a b c d : α)\nvariable (hab : a = b) (hcb : c = b) (hcd : c = d)\n\nexample : a = d :=\n  Eq.trans (Eq.trans hab (Eq.symm hcb)) hcd\n```\nEquality is much more than an equivalence relation, however. It has the important property that every assertion\nrespects the equivalence, in the sense that we can substitute equal expressions without changing the truth value.\nThat is, given `h1 : a = b` and `h2 : p a`, we can construct a proof for `p b` using substitution: `Eq.subst h1 h2`.\nExample:\n```\nexample (α : Type) (a b : α) (p : α → Prop)\n        (h1 : a = b) (h2 : p a) : p b :=\n  Eq.subst h1 h2\n\nexample (α : Type) (a b : α) (p : α → Prop)\n    (h1 : a = b) (h2 : p a) : p b :=\n  h1 ▸ h2\n```\nThe triangle in the second presentation is a macro built on top of `Eq.subst` and `Eq.symm`, and you can enter it by typing `\\t`.\nFor more information: [Equality](https://lean-lang.org/theorem_proving_in_lean4/quantifiers_and_equality.html#equality)\n</code>",
 "2": "<code>Prop</code>",
 "199":
 "<code>unitInterval : Set ℝ</code><span class=\"sep\"></span><code class=\"docstring\">The unit interval `[0,1]` in ℝ. </code>",
 "198": "<code>↑unitInterval</code>",
 "197":
 "<code>Path.{u_1} {X : Type u_1} [TopologicalSpace X] (x y : X) : Type u_1</code><span class=\"sep\"></span><code class=\"docstring\">Continuous path connecting two points `x` and `y` in a topological space </code>",
 "196":
 "<code>JoinedIn.trans.{u_1} {X : Type u_1} [TopologicalSpace X] {x y z : X} {F : Set X} (hxy : JoinedIn F x y)\n  (hyz : JoinedIn F y z) : JoinedIn F x z</code>",
 "195":
 "<code>JoinedIn.symm.{u_1} {X : Type u_1} [TopologicalSpace X] {x y : X} {F : Set X} (h : JoinedIn F x y) : JoinedIn F y x</code>",
 "194": "<code>∀ (t : ↑unitInterval), γ t ∈ A</code>",
 "193": "<code>_root_.Path p2 p3</code>",
 "192": "<code>p3 ∈ A</code>",
 "191": "<code>p2 ∈ A</code>",
 "190":
 "<code>JoinedIn.{u_1} {X : Type u_1} [TopologicalSpace X] (F : Set X) (x y : X) : Prop</code><span class=\"sep\"></span><code class=\"docstring\">The relation \"being joined by a path in `F`\". Not quite an equivalence relation since it's not\nreflexive for points that do not belong to `F`. </code>",
 "19":
 "<code>Nat : Type</code><span class=\"sep\"></span><code class=\"docstring\">The type of natural numbers, starting at zero. It is defined as an\ninductive type freely generated by \"zero is a natural number\" and\n\"the successor of a natural number is a natural number\".\n\nYou can prove a theorem `P n` about `n : Nat` by `induction n`, which will\nexpect a proof of the theorem for `P 0`, and a proof of `P (succ i)` assuming\na proof of `P i`. The same method also works to define functions by recursion\non natural numbers: induction and recursion are two expressions of the same\noperation from Lean's point of view.\n\n```\nopen Nat\nexample (n : Nat) : n &lt; succ n := by\n  induction n with\n  | zero =&gt;\n    show 0 &lt; 1\n    decide\n  | succ i ih =&gt; -- ih : i &lt; succ i\n    show succ i &lt; succ (succ i)\n    exact Nat.succ_lt_succ ih\n```\n\nThis type is special-cased by both the kernel and the compiler:\n* The type of expressions contains \"`Nat` literals\" as a primitive constructor,\n  and the kernel knows how to reduce zero/succ expressions to nat literals.\n* If implemented naively, this type would represent a numeral `n` in unary as a\n  linked list with `n` links, which is horribly inefficient. Instead, the\n  runtime itself has a special representation for `Nat` which stores numbers up\n  to 2^63 directly and larger numbers use an arbitrary precision \"bignum\"\n  library (usually [GMP](https://gmplib.org/)).\n</code>",
 "189": "<code>∀ {y : X}, y ∈ A → JoinedIn A p1 y</code>",
 "188": "<code>p1 ∈ A</code>",
 "187": "<code>TopologicalSpace X</code>",
 "186":
 "<code>IsPathConnected.{u_1} {X : Type u_1} [TopologicalSpace X] (F : Set X) : Prop</code><span class=\"sep\"></span><code class=\"docstring\">A set `F` is path connected if it contains a point that can be joined to all other in `F`. </code>",
 "185":
 "<code>pathConnected_iff.{u_1} {X : Type u_1} [TopologicalSpace X] (A : Set X) : IsPathConnected A ↔ IsPathConnected' A</code><span class=\"sep\"></span><code class=\"docstring\">`IsPathConnected'` is equivalent to Mathlib's\n`IsPathConnected`.\n</code>",
 "184": "<code>↑(Icc 0 1)</code>",
 "183":
 "<code>Continuous.{u, v} {X : Type u} {Y : Type v} [TopologicalSpace X] [TopologicalSpace Y] (f : X → Y) : Prop</code><span class=\"sep\"></span><code class=\"docstring\">A function between topological spaces is continuous if the preimage\nof every open set is open. Registered as a structure to make sure it is not unfolded by Lean. </code>",
 "182":
 "<code>Set.Icc.{u_1} {α : Type u_1} [Preorder α] (a b : α) : Set α</code><span class=\"sep\"></span><code class=\"docstring\">`Icc a b` is the left-closed right-closed interval $[a, b]$. </code>",
 "181": "<code>↑(Icc 0 1) → X</code>",
 "180": "<code>X</code>",
 "18": "<code>P x</code>",
 "179":
 "<code>Set.Nonempty.{u} {α : Type u} (s : Set α) : Prop</code><span class=\"sep\"></span><code class=\"docstring\">The property `s.Nonempty` expresses the fact that the set `s` is not empty. It should be used\nin theorem assumptions instead of `∃ x, x ∈ s` or `s ≠ ∅` as it gives access to a nice API thanks\nto the dot notation. </code>",
 "178": "<code>Set X</code>",
 "177":
 "<code>IsPathConnected'.{u_1} {X : Type u_1} [TopologicalSpace X] (S : Set X) : Prop</code><span class=\"sep\"></span><code class=\"docstring\">An intuitive definition of path connectedness:\nA set `S` is path connected if it is nonempty and any two\npoints in `S` can be joined by a continuous path in `S`.\n</code>",
 "176":
 "<code>TopologicalSpace.{u} (X : Type u) : Type u</code><span class=\"sep\"></span><code class=\"docstring\">A topology on `X`. </code>",
 "175": "<code>Type u_1</code>",
 "174":
 "<code class=\"docstring\">Declares one or more typed variables, or modifies whether already-declared variables are\n  implicit.\n\nIntroduces variables that can be used in definitions within the same `namespace` or `section` block.\nWhen a definition mentions a variable, Lean will add it as an argument of the definition. This is\nuseful in particular when writing many definitions that have parameters in common (see below for an\nexample).\n\nVariable declarations have the same flexibility as regular function parameters. In particular they\ncan be [explicit, implicit][binder docs], or [instance implicit][tpil classes] (in which case they\ncan be anonymous). This can be changed, for instance one can turn explicit variable `x` into an\nimplicit one with `variable {x}`. Note that currently, you should avoid changing how variables are\nbound and declare new variables at the same time; see [issue 2789] for more on this topic.\n\nIn *theorem bodies* (i.e. proofs), variables are not included based on usage in order to ensure that\nchanges to the proof cannot change the statement of the overall theorem. Instead, variables are only\navailable to the proof if they have been mentioned in the theorem header or in an `include` command\nor are instance implicit and depend only on such variables.\n\nSee [*Variables and Sections* from Theorem Proving in Lean][tpil vars] for a more detailed\ndiscussion.\n\n[tpil vars]:\nhttps://lean-lang.org/theorem_proving_in_lean4/dependent_type_theory.html#variables-and-sections\n(Variables and Sections on Theorem Proving in Lean) [tpil classes]:\nhttps://lean-lang.org/theorem_proving_in_lean4/type_classes.html (Type classes on Theorem Proving in\nLean) [binder docs]:\nhttps://leanprover-community.github.io/mathlib4_docs/Lean/Expr.html#Lean.BinderInfo (Documentation\nfor the BinderInfo type) [issue 2789]: https://github.com/leanprover/lean4/issues/2789 (Issue 2789\non github)\n\n## Examples\n\n```lean\nsection\n  variable\n    {α : Type u}      -- implicit\n    (a : α)           -- explicit\n    [instBEq : BEq α] -- instance implicit, named\n    [Hashable α]      -- instance implicit, anonymous\n\n  def isEqual (b : α) : Bool :=\n    a == b\n\n  #check isEqual\n  -- isEqual.{u} {α : Type u} (a : α) [instBEq : BEq α] (b : α) : Bool\n\n  variable\n    {a} -- `a` is implicit now\n\n  def eqComm {b : α} := a == b ↔ b == a\n\n  #check eqComm\n  -- eqComm.{u} {α : Type u} {a : α} [instBEq : BEq α] {b : α} : Prop\nend\n```\n\nThe following shows a typical use of `variable` to factor out definition arguments:\n\n```lean\nvariable (Src : Type)\n\nstructure Logger where\n  trace : List (Src × String)\n#check Logger\n-- Logger (Src : Type) : Type\n\nnamespace Logger\n  -- switch `Src : Type` to be implicit until the `end Logger`\n  variable {Src}\n\n  def empty : Logger Src where\n    trace := []\n  #check empty\n  -- Logger.empty {Src : Type} : Logger Src\n\n  variable (log : Logger Src)\n\n  def len :=\n    log.trace.length\n  #check len\n  -- Logger.len {Src : Type} (log : Logger Src) : Nat\n\n  variable (src : Src) [BEq Src]\n\n  -- at this point all of `log`, `src`, `Src` and the `BEq` instance can all become arguments\n\n  def filterSrc :=\n    log.trace.filterMap\n      fun (src', str') =&gt; if src' == src then some str' else none\n  #check filterSrc\n  -- Logger.filterSrc {Src : Type} (log : Logger Src) (src : Src) [inst✝ : BEq Src] : List String\n\n  def lenSrc :=\n    log.filterSrc src |&gt;.length\n  #check lenSrc\n  -- Logger.lenSrc {Src : Type} (log : Logger Src) (src : Src) [inst✝ : BEq Src] : Nat\nend Logger\n```\n\nThe following example demonstrates availability of variables in proofs:\n```lean\nvariable\n  {α : Type}    -- available in the proof as indirectly mentioned through `a`\n  [ToString α]  -- available in the proof as `α` is included\n  (a : α)       -- available in the proof as mentioned in the header\n  {β : Type}    -- not available in the proof\n  [ToString β]  -- not available in the proof\n\ntheorem ex : a = a := rfl\n```\nAfter elaboration of the proof, the following warning will be generated to highlight the unused\nhypothesis:\n```\nincluded section variable '[ToString α]' is not used in 'ex', consider excluding it\n```\nIn such cases, the offending variable declaration should be moved down or into a section so that\nonly theorems that do depend on it follow it until the end of the section.\n</code>",
 "173":
 "<code class=\"docstring\">A `section`/`end` pair delimits the scope of `variable`, `include, `open`, `set_option`, and `local`\ncommands. Sections can be nested. `section &lt;id&gt;` provides a label to the section that has to appear\nwith the matching `end`. In either case, the `end` can be omitted, in which case the section is\nclosed at the end of the file.\n</code>",
 "172":
 "<code class=\"docstring\">Makes names from other namespaces visible without writing the namespace prefix.\n\nNames that are made available with `open` are visible within the current `section` or `namespace`\nblock. This makes referring to (type) definitions and theorems easier, but note that it can also\nmake [scoped instances], notations, and attributes from a different namespace available.\n\nThe `open` command can be used in a few different ways:\n\n* `open Some.Namespace.Path1 Some.Namespace.Path2` makes all non-protected names in\n  `Some.Namespace.Path1` and `Some.Namespace.Path2` available without the prefix, so that\n  `Some.Namespace.Path1.x` and `Some.Namespace.Path2.y` can be referred to by writing only `x` and\n  `y`.\n\n* `open Some.Namespace.Path hiding def1 def2` opens all non-protected names in `Some.Namespace.Path`\n  except `def1` and `def2`.\n\n* `open Some.Namespace.Path (def1 def2)` only makes `Some.Namespace.Path.def1` and\n  `Some.Namespace.Path.def2` available without the full prefix, so `Some.Namespace.Path.def3` would\n  be unaffected.\n\n  This works even if `def1` and `def2` are `protected`.\n\n* `open Some.Namespace.Path renaming def1 → def1', def2 → def2'` same as `open Some.Namespace.Path\n  (def1 def2)` but `def1`/`def2`'s names are changed to `def1'`/`def2'`.\n\n  This works even if `def1` and `def2` are `protected`.\n\n* `open scoped Some.Namespace.Path1 Some.Namespace.Path2` **only** opens [scoped instances],\n  notations, and attributes from `Namespace1` and `Namespace2`; it does **not** make any other name\n  available.\n\n* `open &lt;any of the open shapes above&gt; in` makes the names `open`-ed visible only in the next\n  command or expression.\n\n[scoped instance]: https://lean-lang.org/theorem_proving_in_lean4/type_classes.html#scoped-instances\n(Scoped instances in Theorem Proving in Lean)\n\n\n## Examples\n\n```lean\n/-- SKI combinators https://en.wikipedia.org/wiki/SKI_combinator_calculus -/\nnamespace Combinator.Calculus\n  def I (a : α) : α := a\n  def K (a : α) : β → α := fun _ =&gt; a\n  def S (x : α → β → γ) (y : α → β) (z : α) : γ := x z (y z)\nend Combinator.Calculus\n\nsection\n  -- open everything under `Combinator.Calculus`, *i.e.* `I`, `K` and `S`,\n  -- until the section ends\n  open Combinator.Calculus\n\n  theorem SKx_eq_K : S K x = I := rfl\nend\n\n-- open everything under `Combinator.Calculus` only for the next command (the next `theorem`, here)\nopen Combinator.Calculus in\ntheorem SKx_eq_K' : S K x = I := rfl\n\nsection\n  -- open only `S` and `K` under `Combinator.Calculus`\n  open Combinator.Calculus (S K)\n\n  theorem SKxy_eq_y : S K x y = y := rfl\n\n  -- `I` is not in scope, we have to use its full path\n  theorem SKxy_eq_Iy : S K x y = Combinator.Calculus.I y := rfl\nend\n\nsection\n  open Combinator.Calculus\n    renaming\n      I → identity,\n      K → konstant\n\n  #check identity\n  #check konstant\nend\n\nsection\n  open Combinator.Calculus\n    hiding S\n\n  #check I\n  #check K\nend\n\nsection\n  namespace Demo\n    inductive MyType\n    | val\n\n    namespace N1\n      scoped infix:68 \" ≋ \" =&gt; BEq.beq\n\n      scoped instance : BEq MyType where\n        beq _ _ := true\n\n      def Alias := MyType\n    end N1\n  end Demo\n\n  -- bring `≋` and the instance in scope, but not `Alias`\n  open scoped Demo.N1\n\n  #check Demo.MyType.val == Demo.MyType.val\n  #check Demo.MyType.val ≋ Demo.MyType.val\n  -- #check Alias -- unknown identifier 'Alias'\nend\n```\n</code>",
 "171": "<code>own_mul_left_neutral (a : ℚ) : (-1) ⊕ a = a</code>",
 "170": "<code>own_mul_right_neutral (a : ℚ) : a ⊕ -1 = a</code>",
 "17": "<code>x = y</code>",
 "169": "<code>own_mul_assoc (a b c : ℚ) : (a ⊕ b) ⊕ c = a ⊕ b ⊕ c</code>",
 "168":
 "<code>Rat : Type</code><span class=\"sep\"></span><code class=\"docstring\">Rational numbers, implemented as a pair of integers `num / den` such that the\ndenominator is positive and the numerator and denominator are coprime.\n</code>",
 "167": "<code>own_mul_komm (a b : ℚ) : a ⊕ b = b ⊕ a</code>",
 "166": "<code><span class=\"literal string\">\" ⊕ \"</span> : String</code>",
 "165": "<code>Lean.TSyntax `term</code>",
 "164": "<code>ℚ</code>",
 "163": "<code>own_add (a b : ℚ) : ℚ</code>",
 "162":
 "<code>HSub.hSub.{u, v, w} {α : Type u} {β : Type v} {γ : outParam (Type w)} [self : HSub α β γ] : α → β → γ</code><span class=\"sep\"></span><code class=\"docstring\">`a - b` computes the difference of `a` and `b`.\nThe meaning of this notation is type-dependent.\n* For natural numbers, this operator saturates at 0: `a - b = 0` when `a ≤ b`. </code>",
 "161":
 "<code class=\"docstring\">The `sorry` term is a temporary placeholder for a missing proof or value.\n\nThe syntax is intended for stubbing-out incomplete parts of a value or proof while still having a syntactically correct skeleton.\nLean will give a warning whenever a declaration uses `sorry`, so you aren't likely to miss it,\nbut you can double check if a declaration depends on `sorry` by looking for `sorryAx` in the output\nof the `#print axioms my_thm` command, the axiom used by the implementation of `sorry`.\n\n\"Go to definition\" on `sorry` in the Infoview will go to the source position where it was introduced, if such information is available.\n\nEach `sorry` is guaranteed to be unique, so for example the following fails:\n```lean\nexample : (sorry : Nat) = sorry := rfl -- fails\n```\n\nSee also the `sorry` tactic, which is short for `exact sorry`.\n</code>",
 "160":
 "<code>Finset.Iic.{u_1} {α : Type u_1} [Preorder α] [LocallyFiniteOrderBot α] (b : α) : Finset α</code><span class=\"sep\"></span><code class=\"docstring\">The finset $(-∞, b]$ of elements `x` such that `x ≤ b`. Basically `Set.Iic b` as a finset. </code>",
 "16": "<code>ℕ → Prop</code>",
 "159":
 "<code>div_two_lt_of_pos.{u_2} {α : Type u_2} [LinearOrderedSemifield α] {a : α} : 0 &lt; a → a / 2 &lt; a</code><span class=\"sep\"></span><code class=\"docstring\">**Alias** of the reverse direction of `half_lt_self_iff`.\n\n---\n\n**Alias** of the reverse direction of `half_lt_self_iff`.</code>",
 "158":
 "<code>half_pos.{u_2} {α : Type u_2} [LinearOrderedSemifield α] {a : α} (h : 0 &lt; a) : 0 &lt; a / 2</code>",
 "157":
 "<code>HDiv.hDiv.{u, v, w} {α : Type u} {β : Type v} {γ : outParam (Type w)} [self : HDiv α β γ] : α → β → γ</code><span class=\"sep\"></span><code class=\"docstring\">`a / b` computes the result of dividing `a` by `b`.\nThe meaning of this notation is type-dependent.\n* For most types like `Nat`, `Int`, `Rat`, `Real`, `a / 0` is defined to be `0`.\n* For `Nat`, `a / b` rounds downwards.\n* For `Int`, `a / b` rounds downwards if `b` is positive or upwards if `b` is negative.\n  It is implemented as `Int.ediv`, the unique function satisfying\n  `a % b + b * (a / b) = a` and `0 ≤ a % b &lt; natAbs b` for `b ≠ 0`.\n  Other rounding conventions are available using the functions\n  `Int.fdiv` (floor rounding) and `Int.tdiv` (truncation rounding).\n* For `Float`, `a / 0` follows the IEEE 754 semantics for division,\n  usually resulting in `inf` or `nan`. </code>",
 "156": "<code>0 &lt; δ</code>",
 "155": "<code>0 &lt; 0 → ∃ n, 1 &lt; n • 0</code>",
 "154":
 "<code>HSMul.hSMul.{u, v, w} {α : Type u} {β : Type v} {γ : outParam (Type w)} [self : HSMul α β γ] : α → β → γ</code><span class=\"sep\"></span><code class=\"docstring\">`a • b` computes the product of `a` and `b`.\nThe meaning of this notation is type-dependent, but it is intended to be used for left actions. </code>",
 "153": "<code>0 &lt; ε</code>",
 "152": "<code>∀ (ε : ℝ), 0 &lt; ε → ∃ n, 1 &lt; n • ε</code>",
 "151": "<code>0 ≤ 0</code>",
 "150": "<code>∀ (n : ℕ), 0 ≤ n</code>",
 "15":
 "<code class=\"docstring\">Introduces one or more hypotheses, optionally naming and/or pattern-matching them.\nFor each hypothesis to be introduced, the remaining main goal's target type must\nbe a `let` or function type.\n\n* `intro` by itself introduces one anonymous hypothesis, which can be accessed\n  by e.g. `assumption`.\n* `intro x y` introduces two hypotheses and names them. Individual hypotheses\n  can be anonymized via `_`, or matched against a pattern:\n  ```lean\n  -- ... ⊢ α × β → ...\n  intro (a, b)\n  -- ..., a : α, b : β ⊢ ...\n  ```\n* Alternatively, `intro` can be combined with pattern matching much like `fun`:\n  ```lean\n  intro\n  | n + 1, 0 =&gt; tac\n  | ...\n  ```\n</code>",
 "149": "<code>p 0</code>",
 "148":
 "<code class=\"docstring\">The tactic `specialize h a₁ ... aₙ` works on local hypothesis `h`.\nThe premises of this hypothesis, either universal quantifications or\nnon-dependent implications, are instantiated by concrete terms coming\nfrom arguments `a₁` ... `aₙ`.\nThe tactic adds a new hypothesis with the same name `h := h a₁ ... aₙ`\nand tries to clear the previous one.\n</code>",
 "147": "<code>∀ (n : ℕ), p n</code>",
 "146": "<code>Option Lean.Term</code>",
 "145": "<code>Lean.TSyntaxArray `rintroPat</code>",
 "144":
 "<code class=\"docstring\">The `rintro` tactic is a combination of the `intros` tactic with `rcases` to\nallow for destructuring patterns while introducing variables. See `rcases` for\na description of supported patterns. For example, `rintro (a | ⟨b, c⟩) ⟨d, e⟩`\nwill introduce two variables, and then do case splits on both of them producing\ntwo subgoals, one with variables `a d e` and the other with `b c d e`.\n\n`rintro`, unlike `rcases`, also supports the form `(x y : ty)` for introducing\nand type-ascripting multiple variables at once, similar to binders.\n</code>",
 "143": "<code>Lean.Elab.Term.TermElabM (α : Type) : Type</code>",
 "142":
 "<code>Lean.MVarId : Type</code><span class=\"sep\"></span><code class=\"docstring\">Universe metavariable Id   </code>",
 "141":
 "<code>Option.{u} (α : Type u) : Type u</code><span class=\"sep\"></span><code class=\"docstring\">`Option α` is the type of values which are either `some a` for some `a : α`,\nor `none`. In functional programming languages, this type is used to represent\nthe possibility of failure, or sometimes nullability.\n\nFor example, the function `HashMap.get? : HashMap α β → α → Option β` looks up\na specified key `a : α` inside the map. Because we do not know in advance\nwhether the key is actually in the map, the return type is `Option β`, where\n`none` means the value was not in the map, and `some b` means that the value\nwas found and `b` is the value retrieved.\n\nThe `xs[i]` syntax, which is used to index into collections, has a variant\n`xs[i]?` that returns an optional value depending on whether the given index\nis valid. For example, if `m : HashMap α β` and `a : α`, then `m[a]?` is\nequivalent to `HashMap.get? m a`.\n\nTo extract a value from an `Option α`, we use pattern matching:\n```\ndef map (f : α → β) (x : Option α) : Option β :=\n  match x with\n  | some a =&gt; some (f a)\n  | none =&gt; none\n```\nWe can also use `if let` to pattern match on `Option` and get the value\nin the branch:\n```\ndef map (f : α → β) (x : Option α) : Option β :=\n  if let some a := x then\n    some (f a)\n  else\n    none\n```\n</code>",
 "140":
 "<code>Lean.TSyntaxArray (ks : Lean.SyntaxNodeKinds) : Type</code><span class=\"sep\"></span><code class=\"docstring\">An array of syntaxes of kind `ks`. </code>",
 "14":
 "<code>Membership.mem.{u, v} {α : outParam (Type u)} {γ : Type v} [self : Membership α γ] : γ → α → Prop</code><span class=\"sep\"></span><code class=\"docstring\">The membership relation `a ∈ s : Prop` where `a : α`, `s : γ`. </code>",
 "139": "<code>Lean.Elab.Tactic.Tactic : Type</code>",
 "138":
 "<code>List.{u} (α : Type u) : Type u</code><span class=\"sep\"></span><code class=\"docstring\">`List α` is the type of ordered lists with elements of type `α`.\nIt is implemented as a linked list.\n\n`List α` is isomorphic to `Array α`, but they are useful for different things:\n* `List α` is easier for reasoning, and\n  `Array α` is modeled as a wrapper around `List α`\n* `List α` works well as a persistent data structure, when many copies of the\n  tail are shared. When the value is not shared, `Array α` will have better\n  performance because it can do destructive updates.\n</code>",
 "137": "<code>Sort ?u.141</code>",
 "136": "<code>Lean.Syntax.Term : Type</code>",
 "135": "<code>?m.128</code>",
 "134":
 "<code>Lean.Name : Type</code><span class=\"sep\"></span><code class=\"docstring\">Hierarchical names consist of a sequence of components, each of\nwhich is either a string or numeric, that are written separated by dots (`.`).\n\nHierarchical names are used to name declarations and for creating\nunique identifiers for free variables and metavariables.\n\nYou can create hierarchical names using a backtick:\n```\n`Lean.Meta.whnf\n```\nIt is short for `.str (.str (.str .anonymous \"Lean\") \"Meta\") \"whnf\"`.\n\nYou can use double backticks to request Lean to statically check whether the name\ncorresponds to a Lean declaration in scope.\n```\n``Lean.Meta.whnf\n```\nIf the name is not in scope, Lean will report an error.\n\nThere are two ways to convert a `String` to a `Name`:\n\n 1. `Name.mkSimple` creates a name with a single string component.\n\n 2. `String.toName` first splits the string into its dot-separated\n    components, and then creates a hierarchical name.\n</code>",
 "133":
 "<code>Lean.Elab.Tactic.RCases.RCasesPatt : Type</code><span class=\"sep\"></span><code class=\"docstring\">An `rcases` pattern can be one of the following, in a nested combination:\n\n* A name like `foo`\n* The special keyword `rfl` (for pattern matching on equality using `subst`)\n* A hyphen `-`, which clears the active hypothesis and any dependents.\n* A type ascription like `pat : ty` (parentheses are optional)\n* A tuple constructor like `⟨p1, p2, p3⟩`\n* An alternation / variant pattern `p1 | p2 | p3`\n\nParentheses can be used for grouping; alternation is higher precedence than type ascription, so\n`p1 | p2 | p3 : ty` means `(p1 | p2 | p3) : ty`.\n\nN-ary alternations are treated as a group, so `p1 | p2 | p3` is not the same as `p1 | (p2 | p3)`,\nand similarly for tuples. However, note that an n-ary alternation or tuple can match an n-ary\nconjunction or disjunction, because if the number of patterns exceeds the number of constructors in\nthe type being destructed, the extra patterns will match on the last element, meaning that\n`p1 | p2 | p3` will act like `p1 | (p2 | p3)` when matching `a1 ∨ a2 ∨ a3`. If matching against a\ntype with 3 constructors,  `p1 | (p2 | p3)` will act like `p1 | (p2 | p3) | _` instead.\n</code>",
 "132":
 "<code>Lean.Syntax : Type</code><span class=\"sep\"></span><code class=\"docstring\">Syntax objects used by the parser, macro expander, delaborator, etc.\n</code>",
 "131": "<code>Sort ?u.63</code>",
 "130": "<code>ty</code>",
 "13":
 "<code>HasSubset.Subset.{u} {α : Type u} [self : HasSubset α] : α → α → Prop</code><span class=\"sep\"></span><code class=\"docstring\">Subset relation: `a ⊆ b`  </code>",
 "129":
 "<code class=\"docstring\">`subst x...` substitutes each `x` with `e` in the goal if there is a hypothesis\nof type `x = e` or `e = x`.\nIf `x` is itself a hypothesis of type `y = e` or `e = y`, `y` is substituted instead.\n</code>",
 "128":
 "<code>rfl.{u} {α : Sort u} {a : α} : a = a</code><span class=\"sep\"></span><code class=\"docstring\">`rfl : a = a` is the unique constructor of the equality type. This is the\nsame as `Eq.refl` except that it takes `a` implicitly instead of explicitly.\n\nThis is a more powerful theorem than it may appear at first, because although\nthe statement of the theorem is `a = a`, Lean will allow anything that is\ndefinitionally equal to that type. So, for instance, `2 + 2 = 4` is proven in\nLean by `rfl`, because both sides are the same up to definitional equality.\n</code>",
 "127":
 "<code class=\"docstring\">`rcases` is a tactic that will perform `cases` recursively, according to a pattern. It is used to\ndestructure hypotheses or expressions composed of inductive types like `h1 : a ∧ b ∧ c ∨ d` or\n`h2 : ∃ x y, trans_rel R x y`. Usual usage might be `rcases h1 with ⟨ha, hb, hc⟩ | hd` or\n`rcases h2 with ⟨x, y, _ | ⟨z, hxz, hzy⟩⟩` for these examples.\n\nEach element of an `rcases` pattern is matched against a particular local hypothesis (most of which\nare generated during the execution of `rcases` and represent individual elements destructured from\nthe input expression). An `rcases` pattern has the following grammar:\n\n* A name like `x`, which names the active hypothesis as `x`.\n* A blank `_`, which does nothing (letting the automatic naming system used by `cases` name the\n  hypothesis).\n* A hyphen `-`, which clears the active hypothesis and any dependents.\n* The keyword `rfl`, which expects the hypothesis to be `h : a = b`, and calls `subst` on the\n  hypothesis (which has the effect of replacing `b` with `a` everywhere or vice versa).\n* A type ascription `p : ty`, which sets the type of the hypothesis to `ty` and then matches it\n  against `p`. (Of course, `ty` must unify with the actual type of `h` for this to work.)\n* A tuple pattern `⟨p1, p2, p3⟩`, which matches a constructor with many arguments, or a series\n  of nested conjunctions or existentials. For example if the active hypothesis is `a ∧ b ∧ c`,\n  then the conjunction will be destructured, and `p1` will be matched against `a`, `p2` against `b`\n  and so on.\n* A `@` before a tuple pattern as in `@⟨p1, p2, p3⟩` will bind all arguments in the constructor,\n  while leaving the `@` off will only use the patterns on the explicit arguments.\n* An alternation pattern `p1 | p2 | p3`, which matches an inductive type with multiple constructors,\n  or a nested disjunction like `a ∨ b ∨ c`.\n\nA pattern like `⟨a, b, c⟩ | ⟨d, e⟩` will do a split over the inductive datatype,\nnaming the first three parameters of the first constructor as `a,b,c` and the\nfirst two of the second constructor `d,e`. If the list is not as long as the\nnumber of arguments to the constructor or the number of constructors, the\nremaining variables will be automatically named. If there are nested brackets\nsuch as `⟨⟨a⟩, b | c⟩ | d` then these will cause more case splits as necessary.\nIf there are too many arguments, such as `⟨a, b, c⟩` for splitting on\n`∃ x, ∃ y, p x`, then it will be treated as `⟨a, ⟨b, c⟩⟩`, splitting the last\nparameter as necessary.\n\n`rcases` also has special support for quotient types: quotient induction into Prop works like\nmatching on the constructor `quot.mk`.\n\n`rcases h : e with PAT` will do the same as `rcases e with PAT` with the exception that an\nassumption `h : e = PAT` will be added to the context.\n</code>",
 "126": "<code>nat</code>",
 "125": "<code>nat.succ (n : nat) : nat</code>",
 "124": "<code>nat.zero : nat</code>",
 "123": "<code>nat : Type</code>",
 "122":
 "<code class=\"docstring\">In Lean, every concrete type other than the universes\nand every type constructor other than dependent arrows\nis an instance of a general family of type constructions known as inductive types.\nIt is remarkable that it is possible to construct a substantial edifice of mathematics\nbased on nothing more than the type universes, dependent arrow types, and inductive types;\neverything else follows from those.\nIntuitively, an inductive type is built up from a specified list of constructors.\nFor example, `List α` is the list of elements of type `α`, and is defined as follows:\n```\ninductive List (α : Type u) where\n| nil\n| cons (head : α) (tail : List α)\n```\nA list of elements of type `α` is either the empty list, `nil`,\nor an element `head : α` followed by a list `tail : List α`.\nSee [Inductive types](https://lean-lang.org/theorem_proving_in_lean4/inductive_types.html)\nfor more information.\n</code>",
 "121": "<code>n = 0 + n</code>",
 "120":
 "<code class=\"docstring\">After `with`, there is an optional tactic that runs on all branches, and\nthen a list of alternatives.\n</code>",
 "12":
 "<code>Real : Type</code><span class=\"sep\"></span><code class=\"docstring\">The type `ℝ` of real numbers constructed as equivalence classes of Cauchy sequences of rational\nnumbers. </code>",
 "119":
 "<code class=\"docstring\">Assuming `x` is a variable in the local context with an inductive type,\n`induction x` applies induction on `x` to the main goal,\nproducing one goal for each constructor of the inductive type,\nin which the target is replaced by a general instance of that constructor\nand an inductive hypothesis is added for each recursive argument to the constructor.\nIf the type of an element in the local context depends on `x`,\nthat element is reverted and reintroduced afterward,\nso that the inductive hypothesis incorporates that hypothesis as well.\n\nFor example, given `n : Nat` and a goal with a hypothesis `h : P n` and target `Q n`,\n`induction n` produces one goal with hypothesis `h : P 0` and target `Q 0`,\nand one goal with hypotheses `h : P (Nat.succ a)` and `ih₁ : P a → Q a` and target `Q (Nat.succ a)`.\nHere the names `a` and `ih₁` are chosen automatically and are not accessible.\nYou can use `with` to provide the variables names for each constructor.\n- `induction e`, where `e` is an expression instead of a variable,\n  generalizes `e` in the goal, and then performs induction on the resulting variable.\n- `induction e using r` allows the user to specify the principle of induction that should be used.\n  Here `r` should be a term whose result type must be of the form `C t`,\n  where `C` is a bound variable and `t` is a (possibly empty) sequence of bound variables\n- `induction e generalizing z₁ ... zₙ`, where `z₁ ... zₙ` are variables in the local context,\n  generalizes over `z₁ ... zₙ` before applying the induction but then introduces them in each goal.\n  In other words, the net effect is that each inductive hypothesis is generalized.\n- Given `x : Nat`, `induction x with | zero =&gt; tac₁ | succ x' ih =&gt; tac₂`\n  uses tactic `tac₁` for the `zero` case, and `tac₂` for the `succ` case.\n</code>",
 "118":
 "<code>Nat.cast_nonneg'.{u_1} {α : Type u_1} [AddMonoidWithOne α] [PartialOrder α] [AddLeftMono α] [ZeroLEOneClass α] (n : ℕ) :\n  0 ≤ ↑n</code><span class=\"sep\"></span><code class=\"docstring\">See also `Nat.cast_nonneg`, specialised for an `OrderedSemiring`. </code>",
 "117":
 "<code class=\"docstring\">An extension of `linarith` with some preprocessing to allow it to solve some nonlinear arithmetic\nproblems. (Based on Coq's `nra` tactic.) See `linarith` for the available syntax of options,\nwhich are inherited by `nlinarith`; that is, `nlinarith!` and `nlinarith only [h1, h2]` all work as\nin `linarith`. The preprocessing is as follows:\n\n* For every subterm `a ^ 2` or `a * a` in a hypothesis or the goal,\n  the assumption `0 ≤ a ^ 2` or `0 ≤ a * a` is added to the context.\n* For every pair of hypotheses `a1 R1 b1`, `a2 R2 b2` in the context, `R1, R2 ∈ {&lt;, ≤, =}`,\n  the assumption `0 R' (b1 - a1) * (b2 - a2)` is added to the context (non-recursively),\n  where `R ∈ {&lt;, ≤, =}` is the appropriate comparison derived from `R1, R2`.\n</code>",
 "116":
 "<code>mul_le_mul_of_nonneg_left.{u_3} {α : Type u_3} {a b c : α} [Mul α] [Zero α] [Preorder α] [PosMulMono α] (h : b ≤ c)\n  (a0 : 0 ≤ a) : a * b ≤ a * c</code>",
 "115":
 "<code>GE.ge.{u} {α : Type u} [LE α] (a b : α) : Prop</code><span class=\"sep\"></span><code class=\"docstring\">`a ≥ b` is an abbreviation for `b ≤ a`. </code>",
 "114": "<code>0 = ↑d * 0</code>",
 "113":
 "<code>zero_le.{u} {α : Type u} [AddZeroClass α] [LE α] [CanonicallyOrderedAdd α] (a : α) : 0 ≤ a</code>",
 "112": "<code>d ≥ 0</code>",
 "111": "<code>False</code>",
 "110":
 "<code>Subtype.{u} {α : Sort u} (p : α → Prop) : Sort (max 1 u)</code><span class=\"sep\"></span><code class=\"docstring\">`Subtype p`, usually written as `{x : α // p x}`, is a type which\nrepresents all the elements `x : α` for which `p x` is true. It is structurally\na pair-like type, so if you have `x : α` and `h : p x` then\n`⟨x, h⟩ : {x // p x}`. An element `s : {x // p x}` will coerce to `α` but\nyou can also make it explicit using `s.1` or `s.val`.\n</code>",
 "11": "<code>x ∈ s</code>",
 "109":
 "<code>mySubtype.mk.{u_1} {ℕ : Sort u_1} (P : ℕ → Prop) (n : ℕ) (hn : P n) : { m // P m }</code>",
 "108":
 "<code>And.intro {a b : Prop} (left : a) (right : b) : a ∧ b</code><span class=\"sep\"></span><code class=\"docstring\">`And.intro : a → b → a ∧ b` is the constructor for the And operation. </code>",
 "107": "<code>R</code>",
 "106":
 "<code>tsum_congr.{u_1, u_2} {α : Type u_1} {β : Type u_2} [AddCommMonoid α] [TopologicalSpace α] {f g : β → α}\n  (hfg : ∀ (b : β), f b = g b) : ∑' (b : β), f b = ∑' (b : β), g b</code>",
 "105":
 "<code>add_comm.{u_1} {G : Type u_1} [AddCommMagma G] (a b : G) : a + b = b + a</code>",
 "104":
 "<code class=\"docstring\">Apply congruence (recursively) to goals of the form `⊢ f as = f bs` and `⊢ HEq (f as) (f bs)`.\nThe optional parameter is the depth of the recursive applications.\nThis is useful when `congr` is too aggressive in breaking down the goal.\nFor example, given `⊢ f (g (x + y)) = f (g (y + x))`,\n`congr` produces the goals `⊢ x = y` and `⊢ y = x`,\nwhile `congr 2` produces the intended `⊢ x + y = y + x`.\n</code>",
 "103": "<code>ℝ → ℝ</code>",
 "102":
 "<code>setOf.{u} {α : Type u} (p : α → Prop) : Set α</code><span class=\"sep\"></span><code class=\"docstring\">Turn a predicate `p : α → Prop` into a set, also written as `{x | p x}` </code>",
 "101": "<code>P n</code>",
 "100": "<code>P → False</code>",
 "10": "<code>ℝ</code>",
 "1": "<code>ℕ</code>",
 "0": "<code>f : ℕ → ℕ</code>"}